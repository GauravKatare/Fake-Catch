{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeAndCatch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yk3PMfBuZhS",
        "colab_type": "text"
      },
      "source": [
        "Make sure GPU is enabled\n",
        "Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhunyJSod_UT",
        "colab_type": "code",
        "outputId": "e9194353-a2b0-4a70-9fb9-b3f82069eed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Clone git repo\n",
        "!git clone https://github.com/CorentinJ/Real-Time-Voice-Cloning.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Real-Time-Voice-Cloning'...\n",
            "remote: Enumerating objects: 2363, done.\u001b[K\n",
            "remote: Total 2363 (delta 0), reused 0 (delta 0), pack-reused 2363\u001b[K\n",
            "Receiving objects: 100% (2363/2363), 360.72 MiB | 41.70 MiB/s, done.\n",
            "Resolving deltas: 100% (1296/1296), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEAy7tlAHDI6",
        "colab_type": "code",
        "outputId": "70638a43-aaaf-438a-fd84-4a66319e6df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install rev-ai\n",
        "!pip install firebase_admin\n",
        "!pip install wget\n",
        "!pip install pydub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rev-ai\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/5c/92e48bdbadcc374f6cb90a93545f5676142b9dabac786f7f492be9c1ea39/rev_ai-2.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from rev-ai) (2.21.0)\n",
            "Collecting enum34==1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Collecting websocket-client==0.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from rev-ai) (1.12.0)\n",
            "Collecting mock==3.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->rev-ai) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->rev-ai) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->rev-ai) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->rev-ai) (2.8)\n",
            "Installing collected packages: enum34, websocket-client, mock, rev-ai\n",
            "Successfully installed enum34-1.1.6 mock-3.0.5 rev-ai-2.7.0 websocket-client-0.56.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting firebase_admin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/b1/ba41c23eb0f7895a4db5a03255bfeec0f54ee8b70374dc68ff2586cafaa5/firebase_admin-3.2.1-py2.py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |████                            | 10kB 29.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 38.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 47.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 40kB 53.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 51kB 57.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 61kB 62.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 71kB 64.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 81kB 65.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.12.0)\n",
            "Collecting google-cloud-storage>=1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/80761781f813ffbf8bc1db7270b6d23de7a96468da4601de3bf2e5e1d829/google_cloud_storage-1.26.0-py2.py3-none-any.whl (75kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 36.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 46.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30kB 56.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 40kB 61.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 51kB 62.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 61kB 67.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 71kB 70.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 14.7MB/s \n",
            "\u001b[?25hCollecting cachecontrol>=0.12.4\n",
            "  Downloading https://files.pythonhosted.org/packages/18/71/0a9df4206a5dc5ae7609c41efddab2270a2c1ff61d39de7591dc7302ef89/CacheControl-0.12.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.16.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.7.11)\n",
            "Collecting google-cloud-firestore>=1.4.0; platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a3/bcde6f5ce12314d6e392c61489c1e5f4b59d2bf23e8e8613a257d6d4c993/google_cloud_firestore-1.6.2-py2.py3-none-any.whl (335kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 60.8MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
            "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
            "Collecting google-auth<2.0dev,>=1.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cachecontrol>=0.12.4->firebase_admin) (2.21.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from cachecontrol>=0.12.4->firebase_admin) (0.5.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (45.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.51.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.27.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.0.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (3.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.18.0->firebase_admin) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.18.0->firebase_admin) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.18.0->firebase_admin) (0.2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (2019.11.28)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=1.11.0->google-cloud-storage>=1.18.0->firebase_admin) (0.4.8)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.7.2, but you'll have google-auth 1.11.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-bigquery 1.21.0 has requirement google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 0.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-cloud-core, google-resumable-media, google-auth, google-cloud-storage, cachecontrol, google-cloud-firestore, firebase-admin\n",
            "  Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Found existing installation: google-auth 1.7.2\n",
            "    Uninstalling google-auth-1.7.2:\n",
            "      Successfully uninstalled google-auth-1.7.2\n",
            "  Found existing installation: google-cloud-storage 1.16.2\n",
            "    Uninstalling google-cloud-storage-1.16.2:\n",
            "      Successfully uninstalled google-cloud-storage-1.16.2\n",
            "Successfully installed cachecontrol-0.12.6 firebase-admin-3.2.1 google-auth-1.11.2 google-cloud-core-1.3.0 google-cloud-firestore-1.6.2 google-cloud-storage-1.26.0 google-resumable-media-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=d9fdcd49735fb8ffec95868958958a8d84208a60c9974afe08e6cde7188079a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GneTTDCIs8TM",
        "colab_type": "code",
        "outputId": "32ee1bdf-8ff7-46ed-9fc2-a78ed405abdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Real-Time-Voice-Cloning/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Real-Time-Voice-Cloning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AVd9vLKeKm6",
        "colab_type": "code",
        "outputId": "f9fa2165-892e-4320-8265-bf340a688e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt\n",
        "!apt-get install -qq libportaudio2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 377.0MB 35kB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 56.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 63.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 63.5MB 45kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 54.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 491kB 64.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 74.7MB/s \n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 145113 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuwgOQlPeN8a",
        "colab_type": "code",
        "outputId": "7e3559ff-9847-436b-ebd2-30995766b819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Download dataset\n",
        "!gdown https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc\n",
        "!unzip pretrained.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc\n",
            "To: /content/Real-Time-Voice-Cloning/pretrained.zip\n",
            "384MB [00:04, 77.1MB/s]\n",
            "Archive:  pretrained.zip\n",
            "   creating: encoder/saved_models/\n",
            "  inflating: encoder/saved_models/pretrained.pt  \n",
            "   creating: synthesizer/saved_models/\n",
            "   creating: synthesizer/saved_models/logs-pretrained/\n",
            "   creating: synthesizer/saved_models/logs-pretrained/taco_pretrained/\n",
            " extracting: synthesizer/saved_models/logs-pretrained/taco_pretrained/checkpoint  \n",
            "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.data-00000-of-00001  \n",
            "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.index  \n",
            "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.meta  \n",
            "   creating: vocoder/saved_models/\n",
            "   creating: vocoder/saved_models/pretrained/\n",
            "  inflating: vocoder/saved_models/pretrained/pretrained.pt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ufTksHH8CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import storage\n",
        "cred = credentials.Certificate('/content/greetup-6a2a3-firebase-adminsdk-ppjba-4905632f7e.json')\n",
        "app = firebase_admin.initialize_app(cred, {\n",
        "  'storageBucket': 'greetup-6a2a3.appspot.com',\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53CWMIQ-eZ-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for recording audio from the browser\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "\n",
        "\n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "\n",
        "  def _repr_html_(self):\n",
        "    from google.colab import output\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "\n",
        "    template = \"\"\"<button id=\"{callback_id}\" style=\"cursor:pointer;background-color:#EEEEEE;border-color:#E0E0E0;padding:5px 15px;font-size:14px\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id)\n",
        "    return html\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  with open('audio.wav','wb+') as f:\n",
        "    f.write(b)\n",
        "  return 'audio.wav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDvZn-k9t3Eu",
        "colab_type": "code",
        "outputId": "c568a6eb-8f33-4629-df59-3928f5333c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "from IPython.display import Audio\n",
        "from IPython.utils import io\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "encoder_weights = Path(\"encoder/saved_models/pretrained.pt\")\n",
        "vocoder_weights = Path(\"vocoder/saved_models/pretrained/pretrained.pt\")\n",
        "syn_dir = Path(\"synthesizer/saved_models/logs-pretrained/taco_pretrained\")\n",
        "encoder.load_model(encoder_weights)\n",
        "synthesizer = Synthesizer(syn_dir)\n",
        "vocoder.load_model(vocoder_weights)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
            "\n",
            "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Found synthesizer \"pretrained\" trained to step 278000\n",
            "Building Wave-RNN\n",
            "Trainable Parameters: 4.481M\n",
            "Loading model weights at vocoder/saved_models/pretrained/pretrained.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyLdbUfks2lv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Deep vocoder\n",
        "def synth(filename,text=\"Donald Trump\"):\n",
        "  #text = \"Donald Trump\" #@param {type:\"string\"}\n",
        "  print(\"Now recording for 10 seconds, say what you will...\")\n",
        "  #record(10)\n",
        "  print(\"Audio recording complete\")\n",
        "  in_fpath = Path(\"/content/\"+filename)\n",
        "  reprocessed_wav = encoder.preprocess_wav(in_fpath)\n",
        "  original_wav, sampling_rate = librosa.load(in_fpath)\n",
        "  preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
        "  embed = encoder.embed_utterance(preprocessed_wav)\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  with io.capture_output() as captured:\n",
        "    specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  audio = Audio(generated_wav, rate=synthesizer.sample_rate)\n",
        "  with open(\"/content/clone_audio.wav\", \"wb\") as fp:\n",
        "        fp.write(audio.data)  \n",
        "  return generated_wav,synthesizer.sample_rate\n",
        "#InvokeButton('Start recording', synth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCYB7qw5n2bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F75qMhYmeb81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import urllib\n",
        "import wget\n",
        "import requests\n",
        "import google.cloud\n",
        "import firebase_admin\n",
        "\n",
        "#proxy = 'http://edcguest:edcguest@172.31.100.14:3128'\n",
        "#os.environ['http_proxy'] = proxy\n",
        "#os.environ['HTTP_PROXY'] = proxy\n",
        "#os.environ['https_proxy'] = proxy\n",
        "#os.environ['HTTPS_PROXY'] = proxy\n",
        "\n",
        "def GetFromCloud(filename):\n",
        "    bucket = storage.bucket(app=app)\n",
        "    blob = bucket.blob(filename)\n",
        "    file_url = blob.generate_signed_url(datetime.timedelta(seconds=300), method='GET')\n",
        "    print(file_url,filename)\n",
        "    r = requests.get(file_url)\n",
        "    print(r.status_code)\n",
        "    if r.status_code != 200:\n",
        "      return False\n",
        "    open(\"/content/\"+filename , 'wb').write(r.content)\n",
        "    return True\n",
        "\n",
        "def SendToCloud(filename):\n",
        "    \n",
        "    bucket = storage.bucket()\n",
        "    imagePath = filename\n",
        "    imageBlob = bucket.blob(\"output.wav\")\n",
        "    imageBlob.upload_from_filename(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj3zqf_-fEgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from rev_ai import apiclient, JobStatus\n",
        "from pydub import AudioSegment\n",
        "import wave\n",
        "\n",
        "#proxy = 'http://edcguest:edcguest@172.31.100.14:3128'\n",
        "\n",
        "#os.environ['http_proxy'] = proxy\n",
        "#os.environ['HTTP_PROXY'] = proxy\n",
        "#os.environ['https_proxy'] = proxy\n",
        "#os.environ['HTTPS_PROXY'] = proxy\n",
        "\n",
        "def mergetwoaudio(mylist,end,training_audio):\n",
        "\n",
        "    sound1 = AudioSegment.from_wav(\"/content/\"+training_audio)\n",
        "    \n",
        "    sound2 = AudioSegment.from_wav(\"/content/clone_audio.wav\")\n",
        "\n",
        "    fro = 0.0\n",
        "    to = 0.0\n",
        "    mixed_sound = sound1[:0]\n",
        "    for ts in mylist:\n",
        "        to = ts[0] * 1000\n",
        "        mixed_sound = mixed_sound + sound1[fro:to] + sound2\n",
        "        fro = ts[1] * 1000\n",
        "\n",
        "    end = end * 1000\n",
        "\n",
        "    mixed_sound = mixed_sound + sound1[fro:end]\n",
        "    mixed_sound.export(\"/content/output.wav\", format='wav')\n",
        "\n",
        "\n",
        "\n",
        "def changeAudio(file_path,sample):\n",
        "    access_token = '02UMSGJJclAaCjsV2JhZn2cVfRiFTo4NBlQtKycPT6k5IxaGNumOSU7a33Bc-uaGXjnXKbo8y1IaVjMHOchz6ua68Lb7U'\n",
        "\n",
        "    # Create client with your access token\n",
        "    client = apiclient.RevAiAPIClient(access_token)\n",
        "\n",
        "    file_job = client.submit_job_local_file(filename= file_path, metadata=\"This_is_some_job_metadata\", callback_url=\"\", skip_diarization=False)\n",
        "\n",
        "    job_id = file_job.id\n",
        "\n",
        "    while file_job.status == JobStatus.IN_PROGRESS :\n",
        "        file_job=client.get_job_details(job_id)\n",
        "    mylist = []\n",
        "    file = client.get_transcript_json(job_id)\n",
        "\n",
        "    end_time = 0.0\n",
        "    sample = sample.lower()\n",
        "    for i in file['monologues']:\n",
        "        for j in i['elements']:\n",
        "            if j['type'] == \"text\":\n",
        "                value_string = j[\"value\"].lower()\n",
        "                if value_string == sample:\n",
        "                    new_tuple = (j[\"ts\"], j[\"end_ts\"])\n",
        "                    mylist.append(new_tuple)\n",
        "                end_time = j[\"end_ts\"]\n",
        "\n",
        "    print(end_time)\n",
        "    return mylist,end_time\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aS5D_dAeVoZ",
        "colab_type": "code",
        "outputId": "e52bb537-bd23-45cd-e8dc-4554ca88bc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This is server running continously\n",
        "import os\n",
        "import time\n",
        "from os import path\n",
        "import shutil\n",
        "from scipy.io.wavfile import write\n",
        "from pydub import AudioSegment\n",
        "# file to be breaked speech.wav\n",
        "#!rm -rf Interface \n",
        "#!git clone https://BhaiChalJa:passwordbhulgaye@github.com/BhaiChalJa/Interface.git\n",
        "while 1 == 1:\n",
        "  if GetFromCloud('input.txt'):      \n",
        "      f= open(\"/content/input.txt\",\"r\")\n",
        "      time.sleep(5)\n",
        "      training_audio = f.readline()\n",
        "      training_audio=training_audio[:-1]\n",
        "      temp=training_audio\n",
        "      training_audio=training_audio+\".mp3\"\n",
        "      GetFromCloud(training_audio)\n",
        "      sound = AudioSegment.from_mp3(\"/content/\"+training_audio)\n",
        "      training_audio=temp+\".wav\"\n",
        "      sound.export(\"/content/\"+training_audio, format=\"wav\")\n",
        "      #training_audio=training_audio[:-3]\n",
        "      #training_audio=training_audio+\"wav\"\n",
        "      training_text = f.readline()\n",
        "      training_text=training_text[:-1]\n",
        "      word_to_be_changed = f.readline();\n",
        "      generated_wav,sample_rate = synth(training_audio,training_text)\n",
        "      print(\"hello\")\n",
        "      print(word_to_be_changed)\n",
        "      if word_to_be_changed==\"NULL\":\n",
        "        shutil.move('/content/clone_audio.wav', '/content/output.wav')\n",
        "      else:    \n",
        "        word_to_be_changed = word_to_be_changed[:-1]\n",
        "        # write('/content/clone_audio.wav', sample_rate, generated_wav)\n",
        "        mylist,end_time = changeAudio(\"/content/\"+training_audio,word_to_be_changed)\n",
        "        mergetwoaudio(mylist,end_time,training_audio)\n",
        "      SendToCloud('/content/output.wav')\n",
        "      break\n",
        "  else:\n",
        "    print(\"File Not Found In System\")\n",
        "    time.sleep(5)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/greetup-6a2a3.appspot.com/input.txt?Expires=1581790826&GoogleAccessId=firebase-adminsdk-ppjba%40greetup-6a2a3.iam.gserviceaccount.com&Signature=knTriSgkTB5VjRZKc9C1S2k0dM4lh3%2Bf2O9t%2FCZhUzRT62ZF6ha2CZnymGdlghsft7SURWdGrl90zog08tytAQbIfqOXduo6zGYpbW0vHFtvy%2FDZKiomX%2FLTKR4fxjgs8p6o%2Fkh7JvoVVVx%2BK%2Bt4zvqE5l8uRSpDWoKNUYlcdtuV4d%2FrF5lVnQeGpFnfMxek1hay79TCJbgK09L1I5Geyz8LSgIa4MGHD9ahDuQzbltNB0wzwF3Dp9jRRApEEzh%2FtNeK3CUWh6Bs0F1YH04O46uf4s0gm9UJ1lLoAP3Uqq8G6tbSEbqJJ5WMoH2z4pDIxs9me7F7OGSb2PtF52kbUQ%3D%3D input.txt\n",
            "200\n",
            "https://storage.googleapis.com/greetup-6a2a3.appspot.com/myFirstTrainingAudio.mp3?Expires=1581790831&GoogleAccessId=firebase-adminsdk-ppjba%40greetup-6a2a3.iam.gserviceaccount.com&Signature=o4EISPoGEMmuyCWjj03YpVpEfPrTQscB9xnf1JPLDIpLxUo4i44Eej8Q6T5d8Zj2pjchIbvQQ411OcLPwbMuLTu3B2sSoupOJrxxwm3xD10i2OVMQfV3yLvreKwwn6vy2ojqQqwHSju8Gm%2BgIecaiCYlsEnpdETGqjeTxP2NWFB2b2en2QyQYMv5e2ymA58foAw3T3UHaT41uxsuBvuSeHb5Ew8uKuMD42fVY87LAj8DHQCbYC9oJecdmWV6c10ArpsbMRJ%2FH%2B7kT7bwqQaTi4fadmnsozZf774KF5XUUXa0qzeLJuPzCOGuPYDSruZjFeOxb3bb9b93%2Fq%2Btj6r1wQ%3D%3D myFirstTrainingAudio.mp3\n",
            "200\n",
            "Now recording for 10 seconds, say what you will...\n",
            "Audio recording complete\n",
            "Synthesizing new audio...\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/inference.py:57: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/tacotron2.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/tacotron2.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/tacotron.py:86: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/tacotron.py:123: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/tacotron.py:135: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:112: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:421: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:422: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:425: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:156: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/attention.py:158: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/attention.py:161: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:305: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/modules.py:269: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f62d68d4b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f62d68d4b00>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f62d68d4b00>>, which Python reported as:\n",
            "    def __call__(self, inputs, state, scope=None):\n",
            "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
            "        \"\"\"\n",
            "        # Apply vanilla LSTM\n",
            "        output, new_state = self._cell(inputs, state, scope)\n",
            "\n",
            "        if self.state_is_tuple:\n",
            "            (prev_c, prev_h) = state\n",
            "            (new_c, new_h) = new_state\n",
            "        else:\n",
            "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\n",
            "\t\t\t\tself._cell._num_proj\n",
            "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
            "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
            "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
            "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
            "\n",
            "        # Apply zoneout\n",
            "        if self.is_training:\n",
            "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\n",
            "\t\t\t# probability to mask activations)!\n",
            "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
            "                                                         (1 - self._zoneout_cell)) + prev_c\n",
            "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
            "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
            "\n",
            "        else:\n",
            "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
            "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
            "\n",
            "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
            "                                                                                                  h])\n",
            "\n",
            "        return output, new_state\n",
            "\n",
            "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
            "WARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f62d6a40c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f62d6a40c18>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f62d6a40c18>>, which Python reported as:\n",
            "    def __call__(self, inputs, state, scope=None):\n",
            "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
            "        \"\"\"\n",
            "        # Apply vanilla LSTM\n",
            "        output, new_state = self._cell(inputs, state, scope)\n",
            "\n",
            "        if self.state_is_tuple:\n",
            "            (prev_c, prev_h) = state\n",
            "            (new_c, new_h) = new_state\n",
            "        else:\n",
            "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\n",
            "\t\t\t\tself._cell._num_proj\n",
            "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
            "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
            "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
            "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
            "\n",
            "        # Apply zoneout\n",
            "        if self.is_training:\n",
            "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\n",
            "\t\t\t# probability to mask activations)!\n",
            "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
            "                                                         (1 - self._zoneout_cell)) + prev_c\n",
            "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
            "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
            "\n",
            "        else:\n",
            "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
            "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
            "\n",
            "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
            "                                                                                                  h])\n",
            "\n",
            "        return output, new_state\n",
            "\n",
            "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/models/tacotron.py:286: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Real-Time-Voice-Cloning/synthesizer/tacotron2.py:62: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000\n",
            "{| ████████████████ 104500/105600 | Batch Size: 11 | Gen Rate: 15.6kHz | }hello\n",
            "NULL\n",
            "\n",
            "10.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T2WQYzV5EvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?Audio"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}